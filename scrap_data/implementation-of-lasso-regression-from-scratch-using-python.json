[
  {
    "input": "Understanding Lasso Regression",
    "output": "Lasso Regression is another linear model derived from Linear Regression, sharing the same hypothetical function for prediction. The cost function of Linear Regression is represented by:\nJ = \\sum_{i=1}^{m} \\left( y^{(i)} - h(x^{(i)}) \\right)^2\nHere\nmis the total number of training examples in the dataset.\nh(x(i))represents the hypothetical function for prediction.\ny(i)represents the value of target variable fori^{\\text{th}}training example.\nor Lasso Regression, the cost function is modified as follows by adding the L1 penalty term:\nJ = \\sum_{i=1}^{m} \\left( y^{(i)} - h(x^{(i)}) \\right)^2 + \\lambda \\sum_{j=1}^{n} |w_j|\nWhere:\nw_j​ represents the weight for thej^{th}feature.\nnis the number of features in the dataset.\nλ is the regularization strength.\nLasso Regression performs both variable selection and regularization by applying an L1 penalty to the coefficients. This encourages sparsity and reducing the number of features that contribute to the final model. Regularization is controlled by the hyperparameter λ.\nIf λ=0 Lasso Regression behaves like Linear Regression.\nIf λ is very large all coefficients are shrunk to zero.\nIncreasing λ increases bias but reduces variance. As it increases more weights are shrunk to zero leading to a sparser model.\nThe model aims to minimize both the sum of the squared errors and the sum of the absolute values of the coefficients. This dual optimization encourages sparsity in the model, leaving only the most important features.\nHere’s how Lasso Regression operates:\nNow we will implement it."
  },
  {
    "input": "Implementation of Lasso Regression in Python",
    "output": "We will use a dataset containing \"Years of Experience\" and \"Salary\" for 2000 employees in a company. We will train a Lasso Regression model to learn the correlation between the number of years of experience of each employee and their respective salary. Once the model is trained we will be able to predict the salary of an employee based on their years of experience. You can download dataset fromhere."
  },
  {
    "input": "1. Importing Libraries",
    "output": "We will be usingnumpy,pandas,scikit learnandmatplotlib."
  },
  {
    "input": "2. Defining Lasso Regression Class",
    "output": "In this dataset Lasso Regression performs bothfeature selectionandregularization. This means that Lasso will encourage sparsity by shrinking less important feature coefficients towards zero and effectively \"pruning\" irrelevant features. In the case of this dataset where the only feature is \"years of experience\" Lasso ensures that this feature is the most significant predictor of salary while any unnecessary noise is eliminated.\n__init__:The constructor method initializes the Lasso Regression model with specifiedlearning_rate,iterationsandl1_penalty.\nfit: The method used to train the model. It initializes the weights (W) and bias (b) and stores the dataset (X,Y).\nX.shape:Returns the dimensions of the feature matrix wheremis the number of training examples andnis the number of features.\nupdate_weights: This method calculates the gradients of the weights and updates them using the learning rate and L1 penalty term (l1_penalty). It uses the prediction (Y_pred) to calculate the gradient for each feature.\ndW[j]:The gradient of the weight for each featurejadjusted for the L1 regularization term.\ndb: Calculates the gradient of the bias term.\nself.Wandself.b:Update weights and bias using the learning rate. This iterative process shrinks weights toward zero encouraging sparsity due to the L1 regularization.\npredict: A method that calculates the predicted output (Y_pred) for the input featuresXby applying the learned weights and bias."
  },
  {
    "input": "3. Training the model",
    "output": "StandardScaler: Standardizes the features (X) by scaling them to have a mean of 0 and standard deviation of 1 which helps in improving the convergence of the gradient descent algorithm.\ntrain_test_split: Splits the dataset into training and testing sets.test_size=1/3means 33% of the data will be used for testing.\nrandom_state=0ensures reproducibility.\nLassoRegressionmodel is initialized with 1000 iterations, learning rate of 0.01 and al1_penaltyof 500. The model is then trained using thefitmethod.\nOutput:\nThis output shows that the Lasso Regression model is successfully fitting the data with a clear linear relationship and it is capable of predicting salaries based on years of experience. The visualization and trained coefficients give insights into how well the model learned from the data. The close match between predicted and real values also shows the model's ability to capture the underlying salary patterns effectively."
  }
]