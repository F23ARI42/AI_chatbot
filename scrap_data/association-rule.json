[
  {
    "input": "Key Components",
    "output": "Antecedent (X): The \"if\" part representing one or more items found in transactions.\nConsequent (Y): The \"then\" part, representing the items likely to be purchased when antecedent items appear.\nRules are evaluated based on metrics that quantify their strength and usefulness:"
  },
  {
    "input": "Rule Evaluation Metrics",
    "output": "1. Support:Fraction of transactions containing the itemsets in both X and  Y.\nSupport measures how frequently the combination appears in the data.\n2. Confidence:Probability that transactions with  X also include Y.\nConfidence measures the reliability of the inference.\n3. Lift:The ratio of observed support to that expected if  X  and  Y  were independent.\nLift > 1 implies a positive association — items occur together more than expected.\nLift = 1 implies independence.\nLift < 1 implies a negative association.\nExample Transaction Data"
  },
  {
    "input": "Considering the rule:",
    "output": "Calculations:\nSupport =\\frac 2 5 = 0.4\nConfidence =\\frac 2 3 \\approx 0.67\nLift =\\frac {0.4}{0.6\\times0.6} = 1.11(positive association)"
  },
  {
    "input": "Implementation",
    "output": "Let's see the working,"
  },
  {
    "input": "Step 1: Install and Import Libraries",
    "output": "We will install and import all the required libraries such aspandas, mixtend,matplotlib,networkx."
  },
  {
    "input": "Step 2: Load and Preview Dataset",
    "output": "We will upload the dataset,\nOutput:"
  },
  {
    "input": "Step 3: Prepare Data for Apriori Algorithm",
    "output": "Apriorirequires thisone-hot encodedformat where columns = items and rows = transactions with True/False flags.\nOutput:"
  },
  {
    "input": "Step 4: Generate Frequent Itemsets",
    "output": "We will,\nFinds itemsets appearing in ≥ 1% of all transactions.\nuse_colnames=True to keep item names readable.\nOutput:"
  },
  {
    "input": "Step 5: Generate Association Rules",
    "output": "We will,\nExtract rules with confidence ≥ 30%.\nRules DataFrame includes columns like antecedents, consequents, support, confidence and lift.\nOutput:\nStep 6: Visualize Top Frequent Items\nWe will,\nVisualizes the 10 most purchased items.\nHelps understand popular products in the dataset.\nOutput:\nStep 7: Scatter Plot of Rules(Support vs Confidence)\nHere we will,\nShows the relationship between support and confidence for rules.\nColor encodes the strength of rules via lift.\nOutput:"
  },
  {
    "input": "Step 8: Heatmap of Confidence for Selected Rules",
    "output": "We will,\nShows confidence values between top antecedent and consequent itemsets.\nA quick way to identify highly confident rules.\nOutput:"
  },
  {
    "input": "Use Cases",
    "output": "Let's see the use case of Association rule,\nMarket Basket Analysis: Identifies products often bought together to improve store layouts and promotions (e.g., bread and butter).\nRecommendation Systems: Suggests related items based on buying patterns (e.g., accessories with laptops).\nFraud Detection: Detects unusual transaction patterns indicating fraud.\nHealthcare Analytics: Finds links between symptoms, diseases and treatments (e.g., symptom combinations predicting a disease).\nInterpretable and Easy to Explain: Rules offer clear “if-then” relationships understandable to non-technical stakeholders.\nUnsupervised Learning: Works well on unlabeled data to find hidden patterns without prior knowledge.\nFlexible Data Types: Effective on transactional, categorical and binary data.\nHelps in Feature Engineering: Can be used to create new features for downstream supervised models.\nLarge Number of Rules: Can generate many rules, including trivial or redundant ones, making interpretation hard.\nSupport Threshold Sensitivity: High support thresholds miss interesting but infrequent patterns; low thresholds generate too many rules.\nNot Suitable for Continuous Variables: Requires discretization or binning before use with numerical attributes.\nComputationally Expensive: Performance degrades on very large or dense datasets due to combinatorial explosion.\nStatistical Significance: High confidence doesn’t guarantee a meaningful rule; domain knowledge is essential to validate findings."
  }
]